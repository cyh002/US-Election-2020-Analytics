{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Presidential Election 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import preprocessing, topic_modeling, deepseek, misc_utils, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration file path\n",
    "config_path = 'conf/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the preprocessing pipeline - Takes very long ~30mins\n",
    "english_tweets = preprocessing.run_preprocessing_pipeline(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_results = topic_modeling.topic_modeling_preprocessing(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Anthony: Ways to get all the keys out!!!\n",
    "# Just need to sum all the values of each dtm to get the word count to create word cloud\n",
    "# Can print to find all the keys\n",
    "# print(dtm_results.keys())\n",
    "# print(dtm_results['vectorizer'].keys())\n",
    "# print(dtm_results['biden'].keys())\n",
    "# print(dtm_results['trump'].keys())\n",
    "# print(dtm_results['both'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to run all the different dtm and their vectorizer\n",
    "training_path = 'conf/train_model.yaml'\n",
    "trump_count_dtm = dtm_results['trump']['count_dtm']\n",
    "count_vect= dtm_results['vectorizer']['count_vectorizer']\n",
    "trump_count_display = train_model.training_pipeline(training_path, dtm= trump_count_dtm, vectorizer=count_vect, random_seed = 1, sample_size = 10000, topn = 10)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(trump_count_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect= dtm_results['vectorizer']['tfidf_vectorizer']\n",
    "trump_tfidf_dtm = dtm_results['trump']['tfidf_dtm']\n",
    "trump_tfidf_display = train_model.training_pipeline(training_path, dtm= trump_tfidf_dtm, vectorizer=tfidf_vect, random_seed = 1, sample_size = 10000, topn = 10)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(trump_tfidf_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_count_dtm = dtm_results['biden']['count_dtm']\n",
    "biden_count_display = train_model.training_pipeline(training_path, dtm= biden_count_dtm, vectorizer=count_vect, random_seed = 1, sample_size = 10000, topn = 10)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(biden_count_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tfidf_dtm = dtm_results['biden']['tfidf_dtm']\n",
    "biden_tfidf_display = train_model.training_pipeline(training_path, dtm= biden_tfidf_dtm, vectorizer=tfidf_vect, random_seed = 1, sample_size = 10000, topn = 10)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(biden_tfidf_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_count_dtm = dtm_results['both']['count_dtm']\n",
    "both_count_display = train_model.training_pipeline(training_path, dtm= both_count_dtm, vectorizer=count_vect, random_seed = 1, sample_size = 10000, topn = 10)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(both_count_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_tfidf_dtm = dtm_results['both']['tfidf_dtm']\n",
    "both_tfidf_display = train_model.training_pipeline(training_path, dtm= both_tfidf_dtm, vectorizer=tfidf_vect, random_seed = 1, sample_size = 10000, topn = 10)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(both_tfidf_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tweets = pd.read_csv('data/english_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure that all the values are present\n",
    "print(english_tweets['tweet'].nunique())\n",
    "print(english_tweets['clean_tweet'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xlm = pd.read_csv('data/results_xlm.csv')\n",
    "print(results_xlm['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xlm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xlm = english_tweets.merge(results_xlm, on= 'clean_tweet', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xlm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the following checks so that make sure all the rows are present\n",
    "print(results_xlm['hashtag'].value_counts())\n",
    "print(results_xlm['sentiment'].unique())\n",
    "assert ((results_xlm['confidence'] >= 0.0) & (results_xlm['confidence'] <= 1.0)).all(),\"Found confidence values outside the range [0.0, 1.0]\"\n",
    "print(results_xlm['clean_tweet'].nunique())\n",
    "print(results_xlm['tweet'].nunique())\n",
    "print(results_xlm['user_followers_count'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill up the na value with unknown for source\n",
    "results_xlm['source'] = results_xlm['source'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_xlm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252563 entries, 0 to 252562\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   created_date          252563 non-null  object \n",
      " 1   created_time          252563 non-null  object \n",
      " 2   tweet_id              252563 non-null  float64\n",
      " 3   tweet                 252563 non-null  object \n",
      " 4   likes                 252563 non-null  int64  \n",
      " 5   retweet_count         252563 non-null  int64  \n",
      " 6   source                252563 non-null  object \n",
      " 7   user_id               252563 non-null  float64\n",
      " 8   user_id_post_count    252563 non-null  int64  \n",
      " 9   user_description      238194 non-null  object \n",
      " 10  days_from_join_date   252563 non-null  int64  \n",
      " 11  user_followers_count  252563 non-null  int64  \n",
      " 12  state                 252563 non-null  object \n",
      " 13  hashtag               252563 non-null  object \n",
      " 14  clean_tweet           252563 non-null  object \n",
      " 15  no_stopwords          252563 non-null  object \n",
      " 16  sentiment             252563 non-null  int64  \n",
      " 17  confidence            252563 non-null  float64\n",
      " 18  engagement            252563 non-null  float64\n",
      "dtypes: float64(4), int64(6), object(9)\n",
      "memory usage: 36.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Engagement function\n",
    "results_xlm['engagement'] = misc_utils.engagement_score(results_xlm['likes'], results_xlm['retweet_count'], results_xlm['user_followers_count'])\n",
    "print(results_xlm.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62233.333333333336\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(results_xlm['engagement'].max())\n",
    "print(results_xlm['engagement'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210817</th>\n",
       "      <td>3148</td>\n",
       "      <td>580</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        likes  retweet_count  user_followers_count\n",
       "210817   3148            580                     6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_xlm[results_xlm['engagement'] == results_xlm['engagement'].max()][['likes', 'retweet_count', 'user_followers_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252563 entries, 0 to 252562\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   created_date          252563 non-null  object \n",
      " 1   created_time          252563 non-null  object \n",
      " 2   tweet_id              252563 non-null  float64\n",
      " 3   tweet                 252563 non-null  object \n",
      " 4   likes                 252563 non-null  int64  \n",
      " 5   retweet_count         252563 non-null  int64  \n",
      " 6   source                252563 non-null  object \n",
      " 7   user_id               252563 non-null  float64\n",
      " 8   user_id_post_count    252563 non-null  int64  \n",
      " 9   user_description      238194 non-null  object \n",
      " 10  days_from_join_date   252563 non-null  int64  \n",
      " 11  user_followers_count  252563 non-null  int64  \n",
      " 12  state                 252563 non-null  object \n",
      " 13  hashtag               252563 non-null  object \n",
      " 14  clean_tweet           252563 non-null  object \n",
      " 15  no_stopwords          252563 non-null  object \n",
      " 16  sentiment             252563 non-null  int64  \n",
      " 17  confidence            252563 non-null  float64\n",
      " 18  engagement            252563 non-null  float64\n",
      " 19  normalized_score      252563 non-null  float64\n",
      "dtypes: float64(5), int64(6), object(9)\n",
      "memory usage: 38.5+ MB\n"
     ]
    }
   ],
   "source": [
    "results_xlm['normalized_score'] = misc_utils.normalization(results_xlm['engagement'], results_xlm['sentiment'], results_xlm['confidence'])\n",
    "results_xlm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11481.187641620636\n",
      "4319.049356877805\n"
     ]
    }
   ],
   "source": [
    "print(results_xlm['normalized_score'].min())\n",
    "print(results_xlm['normalized_score'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between user_followers_count vs likes and retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how many likes and retweets are there when the followers_count =0\n",
    "print(results_xlm[results_xlm['user_followers_count'] == 0][['likes']].value_counts())\n",
    "print(results_xlm[results_xlm['user_followers_count'] == 0][['retweet_count']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Scatter plot for user_followers_count vs likes\n",
    "axes[0].scatter(results_xlm['user_followers_count'], results_xlm['likes'], alpha=0.5)\n",
    "axes[0].set_title('User Followers Count vs Likes', fontsize=14)\n",
    "axes[0].set_xlabel('User Followers Count', fontsize=12)\n",
    "axes[0].set_ylabel('Likes', fontsize=12)\n",
    "\n",
    "# Scatter plot for user_followers_count vs retweet_count\n",
    "axes[1].scatter(results_xlm['user_followers_count'], results_xlm['retweet_count'], alpha=0.5)\n",
    "axes[1].set_title('User Followers Count vs Retweet Count', fontsize=14)\n",
    "axes[1].set_xlabel('User Followers Count', fontsize=12)\n",
    "axes[1].set_ylabel('Retweet Count', fontsize=12)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment distribution among tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment distribution for each hashtag group\n",
    "trump_sentiment = results_xlm[results_xlm['hashtag'] == 'trump']['sentiment'].value_counts()\n",
    "biden_sentiment = results_xlm[results_xlm['hashtag'] == 'biden']['sentiment'].value_counts()\n",
    "both_sentiment = results_xlm[results_xlm['hashtag'] == 'both']['sentiment'].value_counts()\n",
    "\n",
    "# Create a DataFrame to combine all sentiment counts\n",
    "sentiment_df = pd.DataFrame({\n",
    "    'trump': trump_sentiment,\n",
    "    'biden': biden_sentiment,\n",
    "    'both': both_sentiment\n",
    "}).fillna(0)  # Fill NaN with 0 for missing sentiment categories\n",
    "\n",
    "# Plot the sentiment distribution\n",
    "sentiment_df.plot(kind='bar', figsize=(10, 6), width=0.8)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Sentiment Distribution by Hashtag', fontsize=16)\n",
    "plt.xlabel('Sentiment', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "#Make the labels upright\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.legend(title='Hashtag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of days from joined date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(results_xlm['days_from_join_date'], bins=30, edgecolor='black')\n",
    "plt.title('Distribution of Days from Join Date')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment of tweets generated throughout the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'created_time' column is treated as integers (0-23 hours)\n",
    "results_xlm['created_time'] = results_xlm['created_time'].astype(int)\n",
    "\n",
    "# Group by 'created_time' and 'sentiment' to get the sentiment distribution per hour\n",
    "hourly_sentiment_distribution = results_xlm.groupby(['created_time', 'sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot the sentiment distribution as a stacked bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_sentiment_distribution.plot(kind='bar', stacked=True, colormap='viridis', ax=plt.gca())\n",
    "\n",
    "# Add title and axis labels\n",
    "plt.title('Sentiment Distribution Across Hours of the Day', fontsize=16)\n",
    "plt.xlabel('Hour of Day (24-hour format)', fontsize=12)\n",
    "plt.ylabel('Number of Tweets', fontsize=12)\n",
    "\n",
    "# Customize x-axis labels and gridlines\n",
    "plt.xticks(rotation=0)  # Keep x-axis labels upright\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend with a title\n",
    "plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the distribution of sentiment across state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by state and sentiment to count occurrences\n",
    "state_sentiment_distribution = results_xlm.groupby(['state', 'sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Sentiment Distribution per State (Stacked Bar Plot)\n",
    "plt.figure(figsize=(15, 8))\n",
    "state_sentiment_distribution.plot(kind='bar', stacked=True, colormap='viridis', figsize=(15, 8))\n",
    "\n",
    "plt.title('Sentiment Distribution Across States', fontsize=16)\n",
    "plt.xlabel('State', fontsize=12)\n",
    "plt.ylabel('Count of Sentiments', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project6242",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
